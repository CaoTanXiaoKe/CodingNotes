## RST 与 SIGPIPE

### RST 发生的条件
RST 是 TCP 在发生错误时发送的一种 TCP 分节。 产生 RST 的三个条件是：
1. 目的地为某端口的 SYN 到达，然而该端口上没有正在监听的服务器。 
2. TCP 想取消一个已有连接
3. TCP 接收到一个根本不存在的连接上的分节

### connection reset by peer 和 broken pipe
1. 往一个对端已经 close 的通道写数据的时候，对方的TCP会收到这个报文，并且反馈一个 reset 报文。 当收到 reset 报文的时候，继续做 select 读数据的时候就会抛出 connection reset by peer 的异常。
2. 当第一次往一个对端已经 close 的通道写数据的时候会和上面的情况一样，会收到 reset 报文。当再次往这个socket写数据的时候，就会抛出 Broken pipe 了。 根据 TCP 的约定，当收到 reset包的时候，上层必须做出处理，调用将 socket 文件描述符关闭，其实也意味着 pipe 会关闭，因此会抛出这个顾名思义的异常。 

### SIGPIPE 信号
当第一次往一个对端已经 close 的通道上写数据的时候，会收到 reset 报文。 再次写的时候会抛出 Broken pipe。
**规则：**当一个进程向某个已经收到 RST 的套接字执行写操作时，内核向该进程发送一个 SIGPIPE 信号。该信号的默认行为是终止进程，因此进程必须捕获它以免不情愿地被终止。 <br/>
不论该进程捕获了该信号并从其信号处理函数返回，还是简单地忽略该信号，写操作都将返回 EPIPE 错误。<br/>
处理 SIGPIPE 的建议方法取决于它发生时应用想做什么。 如果没有特别的事情要做，那么将信号处理程序直接设置为 SIG_IGN 并假设后续的输出操作将捕捉EPIPE错误并终止。如果信号出现时，需采取特殊措施（可能需在日志文件中登记），那么就必须捕获该信号，以便在信号处理函数中执行所有期望的动作。但是必须意识到，如果我们确实需要知道哪个 write 出了错，那么必须要么不理会该信号，要么从信号处理函数返回后再处理来自write的EPIPE. <br/>
**注：** 如果捕获或者忽略 SIGPIPE 信号 那么第二次写操作返回值 -1， 并将 errno 设置为 EPIPE. `strerr` 和 `perror` 函数将 EPIPE 错误报告为： `Broken pipe`。 总的来说，一个健壮的服务器必须捕获这些 SIGPIPE 信号，并且检查 write 函数调用是否有 EPIPE错误。 


## 静态链接库，动态链接库与链接
链接(linking) 是将各种代码和数据部分收集起来并组合成为一个单一文件的过程。 这个文件可被加载（或被拷贝）到存储器并执行。
1. 链接可以执行于编译时（compile time）， 也就是源代码被翻译成机器代码时。
2. 链接可以执行于加载时（load time）， 也就是在程序被加载器（loader）加载到存储器并执行时；
3. 链接也可以执行于运行时（run time）, 由应用程序来执行。 

### 静态库与动态库
**目标文件：** Linux/Unix 中目标文件有三种形式：
- 可重定位目标文件。包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。 
- 可执行目标文件。 包含二进制代码和数据，其形式可以被直接拷贝到存储器并执行。 
- 共享目标文件。 一种特殊类型的可重定位目标文件，可以在加载或运行时被动态地加载到存储器并链接。 
<br/>

可以把可重定位的目标模块（文件）进行存档(archive), 生成一个单独的文件，称为**静态库（static library）**. 例如有两个 .c 源文件： addvec.c 和 multvec.c 现在把它们存档成一个静态库： libvector.a。可以执行以下命令：<br/>
```
gcc -c addvec.c multvec.c
ar rcs libvector.a addvec.o multvec.o
``` 
动态库也称为**共享库（shared library）**. 例如有两个 .c 源文件： addvec.c 和 multvec.c 现在把它们链接成一个共享库： libvector.so。可以执行以下命令：<br/>
```
gcc -shared -fPIC -o libvector.so addvec.c multvec.c
```
其中， `-fPIC`选项指示编译器生成与位置无关的代码。 

#### 链接静态库
链接静态库的时机是“编译时”， 静态链接主要做了两部分工作： 符号解析和重定位。 
链接器解析引用的时候建立了三个集合： 
- E,可重定位目标文件的集合； 
- U,一个为解析的符号（引用了尚未定义的符号）的集合；
- D,在前面输入文件中已定义的符号集合。 
（详细的符号解析过程参考CSAPP-链接，此处省略几百字），，，
因此关于库的一般准则就是： 将它们放在命令行的结尾。如果需要满足依赖需求，可以在命令行上重复库。 


#### 动态链接
1. 当创建可执行文件时，静态执行一些链接，然后在程序加载时，动态完成链接过程。注意这个过程中，除了一些重定位和符号表信息，没有任何代码和数据拷贝到可执行文件中。 
2. 应用程序还可以在它运行时要求动态链接器加载和链接任意共享库，而无需在编译时连接那些库到应用中。 使用 `dlopen`函数加载和链接共享库。 
```
#include <dlfcn.h>
void* dlopen(const char *filename, int flag);
// 返回：若成功则为指向句柄的指针，若出错则为 NULL. 
```
flag 参数要么是 RTLD_NOW, 该标志告诉链接器立即解析对外部符号的引用，要么包括 RTLD_LAZY 标志，该标志告诉链接器推迟符号解析直到执行来自库中的代码。 

### 目标文件格式
1. 可重定位目标文件
```
			ELF 头
			.text
			.rodata
			.data
			.bass
			.symtab
			.rel.text
			.debug 		// 调试符号表
			.line
			.strtab
			节头部表
```

2. 可执行目标文件
```
			ELF 头部
			段头部表	// 到存储器的映射关系
			.init 		// 程序初始化
			.text
			.rodata
			.data
			.bass
			.symtab
			.debug
			.line
			.strtab
			节头表
```

#### 处理目标文件的工具
- AR
- STRINGS
- STRIP : 从目标文件中删除符号表信息
- NM : 列出一个目标文件的符号表中定义的符号
- SIZE
- READELF
- OBJDUMP
- LDD


### GCC 常用选项

- `gcc -E`： 预处理
- `gcc -S`: 编译
- `gcc -c`: 汇编
- `gcc ` : 链接/(全过程)
- `gcc -g`: 向生成的ELF文件中添加调试信息
- `gcc -D` : 定义宏
- `gcc -U`： 取消宏
- `gcc -I`: 指定搜索头文件的路径
- `gcc -llibrary`: 连接时搜索由 library 命名的库。
- `gcc -L` : 把指定的目录 dir 加到连接程序搜索库文件的路径表中
- `gcc -static` : 指定使用静态连接
- `gcc -O` : 指定优化级别， 默认为 O2 
- `gcc -shared -fPIC -o `: 创建共享库
- `gcc -fno-common` : 告诉链接器，在遇到多重定义的全局符号时，输出一条警告信息。
- `gcc -Wall` : 开启警告


### gdb 调试

#### 调试已运行的程序：
1. 在 Linux 下用 `ps` 或 `pgrep <program>` 查看正在运行的程序的PID(进程ID), 然后用 `gdb <program> PID`格式，挂接正在运行的程序。 
2. 先用 `gdb <program>` 关联上源代码，并运行 gdb, 在 gdb 中用 `attach`命令来挂接进程 PID, 并用 `detach`来取消挂接的进程。

#### 使程序暂停的方式：
1. 设置和显示断点
```
break _linenum_
break _linenum_ if _condition_
break _function_
break _file:linenum_
break _file:function_
break _*address_
break
info break [n]
info breakpoints [n]
```

2. 设置和显示观察点
```
watch _expr_
rwatch _expr_
awatch _expr_
info breakpoints
info watchpoints
```

3. 设置捕捉点
```
catch _event_
event: 
	signal;		signal _signum_;		throw;		catch;
				start;		exit;		load;		unload; 	
```

#### 调试线程：

```
break <linespec> thread <threadno>
break <linespec> thread <threadno> if _condition_
info threads
```

#### 查看栈信息
```
backtrace
bt
bt <n>
up
down
info frame
frame
```

#### 其他查看命令
```
info line
disassembly func
print/f <expr>
print/x <expr>
print/t <expr>
print/d <expr>
display/i $pc
```

### 如何定位内存泄露
1. 静态分析：
	1. 手动检查
		<1>. 读未初始化的存储器
		<2>. 越界
		<3>. 指针悬挂
		<4>. malloc/free, new/delete, new 数组 / delete[] 不匹配或者混用
		<5>. 分配内存与释放内存之间提前 return. 
		<6>. 申请内存与初始化资源管理类（如智能指针shared_ptr）之间被异常截断。
		<7>. 析构函数因抛出异常而被中断。
	2. 静态代码分析工具


2. 动态分析
	1. mtrace 工具
	2. valgrind 工具

## 异常控制流与信号
### 异常控制流
**异常(exception):** 就是控制流中的突变，用来响应处理器状态中的某些变化。 在处理器中，状态被编码为不同的位和信号。状态变化称为事件。在任何情况下，当处理器检测到有事件发生时，它就会通过一张叫做一场表的跳转表，进行一个间接过程调用（异常），到一个专门设计用来处理这类事件的操作体系子程序（异常处理程序：exception handle）。<br/>

异常可以分为四类： 中断，陷阱，故障和终止。 
- 中断是异步发生的，是来自处理器外部的I/O设备的信号的结果。硬件中断不是由任何一条专门的指令造成的，从这个意义上来说，它是异步的。 
- 剩下的异常类型（陷阱，故障和终止）是同步发生的，是执行当前指令的结果。我们把这类指令叫做故障指令（faulting instruction）。<br/> **陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用。**<br/>
**系统调用运行在内核模式中，内核模式允许系统调用执行所有指令，并且可以访问在内核中的栈。**<br/>
**所有到Linux系统调用的参数都是通过寄存器而不是栈传递的。** <br/>

**进程：** 就是一个执行中的程序的实例。由内核来调度和维护，有独立的虚拟地址空间，想要和其他流通信，控制流必须使用某种显示的[IPC机制]()。 系统中的每个程序都是运行在某个进程的上下文中的。 上下文是由程序正确执行所需的状态组成的。这个状态包括存放在存储器中的程序的代码和数据，它的栈，通用目的寄存器的内容，程序计数器，环境变量以及打开的文件描述符的集合。 <br/>

进程提供给应用程序两个关键的抽象：
1. 一个独立的逻辑控制流；它提供一个假象，好像我们的程序独占地使用处理器。 
2. 一个私有的地址空间；它提供一个假象，好像我们的程序独占地使用存储器系统。

进程从用户模式变为内核模式的唯一方法是通过诸如中断，故障或者陷入系统调用这样的异常。当异常发生时，控制传递到异常处理程序，处理器将模式从用户模式变为内核模式。异常处理程序运行在内核模式中，当它返回到应用程序代码时，处理器就把模式从内核模式改回到用户模式。 


### 信号
**信号**就是一条短消息，它通知进程系统中发生了一个某种类型的事件。 每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。 <br/>

发送信号到目的进程是由两个步骤组成的：
1. 发送信号。 内核通过更新目的进程上下文中的某个状态，发送（递送）一个信号给目的进程。 发送信号可以有如下两个原因：
	- 内核检测到一个系统事件，比如被零除错误或者子进程终止。
	- 一个进程调用 kill 函数， 显式地要求内核发送一个信号给目的进程。 一个进程可以发送信号给它自己。 
2. 接收信号。当目的进程被内核强迫以某种方式对信号的发送做出反应时，目的进程就接收了信号。进程可以忽略这个信号，终止或者通过执行一个称为信号处理程序的用户层函数捕获这个信号。 一个只发出而没有被接收的信号叫做待处理信号。 在任何时刻，一种类型至多只会有一个待处理信号。 <br/>	

一个待处理信号最多只能被接收一次。内核为每个进程在 pending 位向量中维护着待处理信号的集合，而在 blocked 位向量中维护着被阻塞信号集合。 只要传送了一个类型为 k 的信号， 内核就会设置 pending 中的第 k 位，而只要接收了一个类型为 k 的信号，内核就会清除 pending 中的第 k 位。 <br/>

**接收信号的过程：**
当内核从一个异常处理程序返回，准备将控制传递给进程 p 时， 它会检查进程 p 的未被阻塞的待处理信号的集合（pending &~ blocked）， 如果这个集合为空（通常情况下），那么内核将控制传递到 p 的逻辑控制流中的下一条指令。 
然而，如果集合是非空的，那么内核选择集合中的某个信号 k (通常是最小的 k), 并强制 p 接收信号 k. 收到这个信号会触发进程的某个行为。一旦进程完成了这个行为，那么控制就传递回 p 的逻辑控制流中的下一条指令(Inext)。 
<br/>
每个信号类型都有一个预定义的默认行为，是下面中的一种：
- 进程终止
- 进程终止并转储存储器（dump core）
- 进程停止直到被SIGCONT 信号重启
- 进程忽略该信号


**进程可以通过signal 函数修改和信号相关联的默认行为。唯一的例外是 SIGSTOP 和 SIGKILL, 它们的默认行为是不能被修改的。**

<br/>

**信号处理问题**

- 待处理信号不会排队等待。任意类型至多只有一个待处理信号。 
- 系统调用可以被中断。 

[内核是如何发送信号到应用进程的](http://chenwenke.cn/blog/2017/07/06/core-send-signals-to-process/)

### 文件
在 Unix 中， 所有的 I/O 设备， 如网络，磁盘，终端，都被模型化为文件， 而所有的输入和输出都要被当作对相应文件的读和写来执行。 

- **打开文件。** 一个应用程序通过要求内核打开相应的文件，来宣告它想要访问一个I/O设备。 内核返回一个小的非负整数，叫描述符，它在后续对此文件的所有操作中标识这个文件。内核记录有关这个打开文件的所有信息。应用程序只需记住这个描述符。 

- **改变当前文件的位置。** 对于每个打开的文件，内核保持着一个文件位置 k, 被初始化为 0. 这个文件位置是从文件开头起始的字节偏移量。 应用程序能够通过执行 seek 操作，显式地设置文件的当前位置为 k。 

- **关闭文件。** 当应用完成了对文件的访问之后，它就通知内核关闭这个文件。 作为响应，内核释放文件打开时创建的数据结构，并将这个描述符恢复到可用的文件描述符池中。无论一个进程因为何种原因终止时，内核都会关闭所有打开的文件并释放它们的存储器资源。


某些情况下， read 和 write 传送的字节比应用程序的要求的要少。这些不足值不表示有错误。出现这种情况的原因如下：
- 读时遇到 EOF。 
- 从终端读文本行。
- 读和写网络套接字。 如果打开的文件对应于网络套接字，那么内部缓冲约束和较长的网络延迟会引起 read 和 write 返回不足值。 对管道调用 read 和 write时， 也有可能出现不足值。 

实际上，除了 EOF, 你在读磁盘文件时将不会遇到不足值，而且在写磁盘文件时，也不会遇到不足值。 然而如果你想要创建健壮的（可靠的）诸如Web服务器这样的网络应用，就必须反复调用 read 和 write 处理不足值，直到所有的字节都传送完毕。 

#### 打开文件的数据结构
**内核用三个相关的数据结构来表示打开的文件。**

- 描述符表。 每个进程都有它独立的描述符表，它的表项是由进程打开的文件描述符来索引的。 每个打开的描述符表项指向文件表中的一个表项。

- 文件表。 打开文件的集合是由一张文件表来表示的，所有的进程共享这张表。每个文件表的表项组成（针对我们的目的）包括有当前的文件位置，引用计数（即当前指向该表项的描述符表项数），以及一个指向 v-node 表中对应表项的指针。 关闭一个描述符会减少相应的文件表表项中的引用计数。 内核不会删除这个文件表表项，直到它的引用计数为零。

- v-node 表。 同文件表一样，所有的进程共享这张 v-node 表。 每个表项包含 stat 结构中的大多数信息， 包括 st-mode 和 st-size成员。


在调用 fork 后， 子进程有一个父进程描述符表的副本。父子进程共享相同的打开文件表集合，因此共享相同的文件位置。（一个很重要的结果就是，在内核删除相应文件表表项之前，父子进程必须都关闭了它们的描述符。）

![打开文件的数据结构]()


### 文件系统
i 节点是固定长度的记录项，它包含有关文件的大部分信息。
1. 每个 i 节点中都有一个链接计数，其值是指向该 i 节点的目录项数。
2. i 节点包含了文件有关的所有信息：文件类型，文件访问权限位，文件长度和指向文件数据块的指针等。

stat 结构中的大多数信息都取自 i 节点。 只有两项重要的数据存放在目录项中：文件名和 i 节点编号。 

- [i 节点结构]()

符号链接是对一个文件的间接指针。硬链接直接指向文件的 i 节点。 引入符号链接的原因是为了避免硬链接的一些限制。

1. 硬链接通常要求链接和文件位于同一文件系统中。
2. 只有超级用户才能创建指向目录的硬链接（在底层文件系统支持的情况下）。 



#### 标准IO与文件IO

**文件I/O：**  文件I/O称之为不带缓存的I/O（unbuffered I/O)。不带缓存指的是每个read，write都调用内核中的一个系统调用。也就是一般所说的低级I/O——操作系统提供的基本IO服务，与os绑定。

标准I/O： 标准I/O是ANSI C建立的一个标准I/O模型，是一个标准函数包和stdio.h头文件中的定义，具有一定的可移植性。标准I/O库处理很多细节。例如缓存分配，以优化长度执行I/O等。标准的I/O提供了三种类型的缓存。
- 全缓存
- 行缓存
- 不缓存

标准I/O库将一个打开的文件模型化为一个流。 对于程序员而言，一个流就是一个指向FILE类型的结构指针。 <br/>
类型为FILE的流是对文件描述符和流缓冲区的抽象。流缓冲区的目的是为了减少开销较高的Unix I/O系统调用的数量。 

[标准IO VS 文件IO](http://chenwenke.cn/blog/2017/05/05/fileIO-VS-standardIO/)

### 库函数与系统函数的区别
库函数是语言本身的一部分，而系统函数是内核提供给应用程序的接口，属于操作系统的一部分。
1. 库函数在所有的 ANSI C 编译器版本中，C 库函数是相同的。 各个操作系统的系统调用是不同的。
2. 库函数是调用函数库的一段程序。 系统调用是调用系统内核的服务。 
3. 库函数与用户程序相关联。 系统调用是操作系统的一个入口点。
4. 库函数在用户地址空间执行。 系统调用在内核地址空间执行。
5. 库函数属于过程调用，调用开销较小。 系统调用需要在用户空间和内核上下文环境间切换，开销较大。 
6. 库函数有 300 多个。 系统调用有 90 多个。
7. 库函数的运行时间属于 “用户时间”。 系统调用的运行时间属于“系统时间”。 
8. 库函数例子：system, fprintf, malloc; 系统调用：fork, write, brk. 
9. 有些库函数封装了系统调用。 

### 守护进程
守护进程(daemon)是后台运行且不与任何控制终端关联的进程。守护进程的生存期一般都很长，它们常常在系统引导装入时启动，仅仅在系统关闭时才终止。

另外，应当注意的是用户层的守护进程的父进程都是 init进程。
#### 守护进程的编程规则：
1. 首先要做的是调用 umask 将文件模式创建屏蔽字设置为一个已知值（通常是 0）.
2. 调用 fork，然后使父进程 exit. 使得当前进程的父进程是 init 进程。
3. 调用 setsid创建一个新会话。 
4. 调用 fork， 然后使父进程 exit. 使得当前进程不是该会话里的首进程，因而不会和终端相联。 
5. 更改当前工作目录为根目录（或其他目录，一般是根目录）
6. 关闭不再需要的文件描述符。
7. 如果有输入输出，重定向文件描述符0，1，2到文件/dev/null。  

### 进程间通信(IPC)
IPC方式： 管道，FIFO，消息队列，信号量，共享存储，网络IPC:套接字，远程过程调用(RPC)。

#### 1. 管道： 
管道通常是半双工的，只能在具有公共祖先的两个进程之间使用。 
- 数据通常需要通过内核在管道中流动（和套接字一样，是以字节流的形式传输的）。 
- 通常进程会先调用 pipe， 接着调用 fork, 从而创建从父进程到子进程的IPC通道。
- 当读(read)一个写端已被关闭的管道时，在所有数据都被读取后，read 返回 0，表示文件结束。
- 如果(write)一个读端已被关闭的管道，则产生信号 SIGPIPE. 如果忽略该信号或者捕获该信号并从其处理程序返回，则write返回-1， errno 设置为 EPIPE。

#### 2. FIFO: 
FIFO又称为**有名管道**. 不要求两个进程之间有共同的祖先。创建 FIFO类似于创建文件。确实，FIFO的路径名存在于文件系统中。

- 在一般情况下(没有指定 O_NONBLOCK)， 只读 open 要阻塞到某个其他进程为写而打开这个FIFO为止。类似地，只写 open 要阻塞到某个其他进程为读而打开它为止。
- 如果指定了 O_NONBLOCK， 则只读 open 立即返回。但是，如果没有进程为读而打开一个 FIFO, 那么只写 open 将返回 -1, 并将 errno 设置为 ENXIO.   

类似于管道，若 write一个尚无进程为读而打开的 FIFO, 则产生信号 SIGPIPE. 若某个FIFO的最后一个写进程关闭了该 FIFO, 则将为该 FIFO 的读进程产生一个文件结束标志。

FIFO 有以下两种用途：
1. shell 命令使用 FIFO 将数据从一条管道传送到另一条时，无需创建中间临时文件。
2. 客户进程-服务器进程应用程序中，FIFO用作汇聚点，在客户进程和服务器进程二者之间传递数据。 

#### 3. 消息队列：
消息队列是消息的链接表，存储在内核中，由消息队列标识符标记。 
新消息总是放在队列尾端，但我们并不一定要以先进先出的次序取消息，也可以按消息的类型取消息。 

#### 4. 信号量：
信号量是一个计数器，用于为多个进程提供对共享数据的访问。信号量值的测试及减一操作应当是原子操作。

posix 信号量有两种形式：命名的和未命名的。它们的差异在创建和销毁的形式上，但其它工作一样。未命名信号量只存在于内存中，并要求能使用信号量的进程必须可以访问内存。这意味着它们只能应用在同一个进程中的线程或者不同进程中已经映射相同内存内容到它们地址空间中的线程。相反，命名信号量可以通过名字访问，因此可以被任何已知它们名字的进程中的线程使用。 <br/>
如果进程没有调用 sem_close 而退出，那么内核将自动关闭任何打开的信号量。 注意，这不会影响信号量值的状态 —— 如果已经对它进行了增 1 操作，这不会因为退出而改变。类似地，如果调用 sem_close, 信号量值也不会收到影响。<br/>
sem_unlink 函数删除信号量的名字。 如果没有打开的信号量引用，则信号量会被销毁。否则，销毁将延迟到最后一个打开的引用关闭。

#### 5. 共享存储：
共享存储允许两个或多个进程共享一个给定的存储区。因为数据不需要在客户进程和服务器进程之间复制，即避免了来回的从内核缓冲区复制数据到用户进程缓冲区的开销，所以这是最快的一种 IPC。 默认情况下，共享存储段紧靠在栈之下。通过 mmap 函数也能实现共享存储的作用，两者之间的主要区别是，用 mmap 映射的存储器段是与文件相关联的，而 XSI共享存储段并无这种关联。

如果在多个进程间共享同一个资源，则可以用这三种技术中的一种来协调访问。我们可以使用映射到两个进程地址空间中的信号量，记录锁或者互斥量。

#### 关于使用IPC时的一些建议：

要学会使用管道和FIFO，因为这两种基本技术仍可有效地应用于大量的应用程序。在新的应用程序中，要尽可能避免使用消息队列以及信号量，而应当考虑全双工管道和记录锁，它们使用起来会简单的多。共享存储仍有它的用途，虽然通过 mmap 函数也能提供同样的功能。

#### mmap 函数
mmap 函数把文件或一个POSIX共享内存区对象映射到调用进程的地址空间。使用该函数有三个目的：
1. 使用普通文件以提供内存映射I/O。 
2. 使用特殊文件以提供匿名内存映射。
3. 使用 shm_open 以提供无亲缘关系进程间的POSIX共享内存区。 

```
void *mmap(void *addr, size_t len, int prot, int flags, int fd, off_t offset); 
						返回：若成功则为被映射区的起始地址，若出错则为 MAP_FAILED. 
```

**flags:**

- 如果 flags 为 map_private, 那么调用进程对被映射数据所作的修改只对该进程可见，而不改变其底层支撑对象（或是一个文件对象，或者是一个共享内存区对象）。 
- 如果 flags 为 map_shared, 那么调用进程对被映射数据所作的修改对于共享该对象的所有进程都可见，而且确实改变了其底层支撑对象。

由于物理页与虚拟页之间同步的方式是写回式，有时我们为了确保磁盘文件与内存中数据一致，可以调用：
```
int msync(void *addr, size_t len, int flags); 
```

不是所有文件都能进行内存映射。例如，试图把一个访问终端或套接字的描述符映射到内存将导致 mmap 返回一个错误。 这些类型的描述必须使用 read 和 write(或者它们的变体)来访问。

[mmap映射文件图]()

POSIX 1 提供了两种在无亲缘关系进程间共享内存区的方法：
1. 内存映射文件： 由 open 函数打开，由 mmap 函数把得到的描述符映射到当前地址空间中的一个文件。内存映射文件也可以在无亲缘关系的进程间共享。
2. 共享内存区对象： 由 shm_open 打开一个 POSIX 1 IPC 名字（也许是文件系统中的一个路径名），所返回的描述符由 mmap 函数映射到进程的地址空间。


### 虚拟存储器
虚拟存储器是对主存的抽象。 虚拟存储器是硬件异常，硬件地址翻译，主存，磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的，一致的和私有的地址空间。 通过一个很清晰的机制，虚拟存储器提供了三个重要的能力：
1. 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。
2. 它为每个进程提供了一致的地址空间，从而简化了存储器管理。
3. 它保护了每个进程的地址空间不被其他进程破坏。 

处理器通过虚拟寻址的方式访问主存，虚拟地址在被送到存储器之前会被 MMU(存储器管理单元)根据页表转换成物理地址，进而访问物理地址所指向的数据对象。

虚拟地址空间，就是一个非负整数地址的有序集合。 32位系统中这个额集合的大小是 2^32(4G), 现在的 64位系统 i7 处理器中这个集合的大小是 2^48(256T)。这就说明数据对象和它们的地址是分离的，也就是说一个数据对象可以对应多个虚拟地址。


概念上而言，虚拟存储器（VM）被组织为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组。 每个字节都有一个唯一的虚拟地址，这个唯一的虚拟地址是所为到数组的索引的。 虚拟存储器系统把虚拟存储器分割成虚拟页，物理存储器也被分割成与其相同大小的物理页，Linux中这个数字是 4K. 物理存储器作为虚拟存储器的缓存，它们之间数据传输的基本单元就是页。这个页面传输的过程由虚拟存储器机制来完成。


在任何时刻，虚拟页面的集合都分为三个不相交的子集。 
1. 未分配的： 虚拟存储器系统还未分配(或创建)的页。 未分配的页没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
2. 缓存的： 当前缓存在物理存储器中的已分配页。 
3. 未缓存的： 没有缓存在物理存储器中的已分配页。 

虚拟页是通过一个页表映射到物理页的。 页表就是一个页表条目的数组。每个页表条目前面是一些控制位和标志位，如控制用户访问权限，可读，可写，标志后面的地址是虚拟页地址还是物理页地址的位。后面存的是地址，如果已经缓存了就是物理首地址，如果没有缓存就是虚拟页的首地址。 

如果访问未被缓存的虚拟页，会发生缺页异常，引起页面调度。现代的系统都是按需调度的方式，也就是一直等到不命中发生时，才换入页面。 

1. 操作系统为每个进程提供了一个独立的页表，因而每个进程都有一个独立的虚拟地址空间。
2. 虚拟简化链接： 独立的地址空间允许每个进程的存储器映像使用相同的基本格式，而不管代码和数据实际存放在物理存储器的何处。这样的一致性允许链接器生成全链接的可执行文件，这些可执行文件是独立于物理存储器中的代码和数据的最终位置的。
3. 简化加载：在程序加载时，Linux 加载器分配虚拟页的一些片并将这些虚拟页标记为未被缓存的，将页表条目指向目标文件中适当的位置。加载器从不实际拷贝任何数据从磁盘到存储器，在每个页面初次被引用时，虚拟存储器系统会按照需要自动地调入数据页。
4. 简化共享：独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。
5. 简化存储器分配： 当一个运行在用户进程中的程序要求额外的堆空间时，操作系统分配一个适当的数字的虚拟存储器页面，并且将它们映射到物理存储器中任意位置的 k 个任意的物理页面。由于页表工作的方式，操作系统没有必要分配 k 个连续的物理存储器页面。页面可以随机地分散在物理存储器中。 

- [漫谈：虚拟存储器]()

内核为系统中的每个进程维护一个单独的任务结构（源代码中的 task_struct）。 任务结构中的元素包含或者指向内核运行该进程所需要的所有信息(例如，PID, 指向用户栈的指针，可执行目标文件的名字以及程序计数器)。 

[内核中的 vm数据结构]()

task_struct 中的一个条目指向 mm_struct, 它描述了虚拟存储器的当前状态。 其中 pgd 指向第一级页表（页全局目录）的基址。 而 mmap 指向一个 vm_area_structs (区域结构)的链表， 其中每个 vm_area_structs 都描述了当前虚拟地址空间的一个区域（area）。 

- vm_start: 指向这个区域的起始处。
- vm_end:	指向这个区域的结束处。 
- vm_prot:  描述这个区域包含的所有页的读写许可权限。 
- vm_flags: 描述这个区域的页面是与其他进程共享的，还是这个进程私有的。 
- vm_next:  指向链表中下一个区域结构。


### 线程同步
一个线程所特有的数据: 线程ID, 栈, 栈指针，通用目的寄存器，程序计数器，条件码，信号屏蔽字，线程优先级。

1. 信号量： 信号量就是一个计数器，不过其加减操作都是原子操作。 原子操作是内核用一条计算机指令 CAS: compare and swap(set) 进行实现的, 由于是一条计算机指令，所以不会出现 ABA问题。

2. 互斥量： 互斥量从本质上来说是一把锁，在访问共享资源前对互斥量进行设置（加锁），在访问完成后释放（解放）互斥量。相当于二值信号量。

3. 条件变量： 条件变量给多个线程提供了一个会合的场所，条件本身是由互斥量保护的。条件变量与互斥量一起使用时，允许线程以无竞争的方式等待特定的条件发生，进而调度对共享资源的访问。

4. 读写锁：与互斥量类似，不过读写锁允许更高的并行性。互斥量要么是锁住状态，要么就是不加锁状态，而且一次只有一个线程可以对其加锁。读写锁可以有 3 种状态：读模式下加锁状态，写模式下加锁状态，不加锁状态。 一次只有一个线程可以占有写模式下的读写锁，但是多个线程可以同时占有读模式下的读写锁。 读写锁非常适合于对于数据结构读的次数远大于写的情况。

5. 自旋锁：自旋锁与互斥量类似，但它不是通过休眠使进程阻塞，而是在获取锁之前一致处于忙等（自旋）阻塞状态。自旋锁可用于以下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多的成本。 另外：自旋锁通常作为底层原语用于实现其他类型的锁。

6. 屏障： 屏障(barrier)是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有合作线程都到达某一点，然后从该点继续执行。

7. 记录锁：记录锁的功能是: 当第一个进程正在读或修改文件的某个部分时，使用记录锁可以阻止其他进程修改同一文件区。更确切地说，记录锁是字节范围锁，因为它锁定的只是文件中的一个区域（也可能是整个文件）。不同进程之间共享性读锁和独占性写锁。对于同一进程而言，对同一文件区域重复加锁，新锁替换旧锁。
在设置或释放文件上的一把锁时，系统按要求组合或分裂相邻区。

#### 锁的隐含继承和释放： 
1. 锁与进程和文件相关联。这有两重含义：第一重很明显，当一个进程终止时，它所创建的锁全部释放；第二重则不太明显，无论一个描述符何时关闭，该进程通过这一描述符引用文件上的任何一把锁都会释放（这些锁都是该进程设置的），也就是说：该进程对该文件加的所有读写锁都会被释放（dup也好， open也好，全玩儿完）。 
2. 由 fork 产生的子进程不继承父进程所设置的锁。 
3. 在执行 exec 后， 新进程可以继承原执行程序的锁。但是注意，如果对一个文件描述符设置了执行时关闭标志，那么作为exec的一部分关闭文件描述符时，将释放相应文件的所有锁。

#### 建议锁和强制锁： 
1. 建议性锁： 建议锁需要所有对文件的访问操作都使用统一函数（加了锁的），但是它不能阻止另一个不使用这些加锁函数而且对相应文件有修改权限的进程破坏锁的机制。 
2. 强制性锁：强制性锁会让内核检查每一个 open, read 和 write，验证调用进程是否违背了长在访问的文件的某一把锁。(Linux 中需要在各文件系统基础上用 mount -o mand 命令打开强制性锁机制)。

#### 比较
什么时候选用读写锁，什么时候选用自选锁，什么时候选用屏障，这些判断条件都很明确。 下面讨论一下什么时候选用 互斥锁，条件变量，信号量，记录锁的情况。

互斥锁必须总是由给它上锁的线程解锁，而信号量的wait和post不必由同一线程执行。
互斥要么被锁住，要么被解开，和二值信号量类似。
条件变量在发送信号时，如果没有线程在等待该条件变量，那么信号将丢失；而信号量有计数值，每次信号量 post操作都会被记录。
（信号量）sem_post 是各种同步技巧中，唯一一个能在信号处理程序中安全调用的函数。
互斥锁是为上锁而优化的；条件变量是为等待优化的；信号量即可用于上锁，也可用户等待，因此会有更多的开销和更好的复杂性。
在对进程间共享内存区进行同步时，用记录锁比较好些，因为它语法简单明确，不易出错。

### 线程安全
**可重入函数：** 当它们被多个线程调用时，不会引用任何共享数据。 可重入函数是线程安全函数的真子集。

四类(不相交的)线程不安全函数：

- 不保护共享变量的函数。 ——> 解决方法： 加锁同步。
- 保持跨越多个调用状态的函数。例如 rand()。 ——> 解决方法： 重写，使它不再使用任何 static 数据， 而是依靠调用者在参数中传递状态信息。
- 返回指向静态变量的指针的函数。 如 ctime()。 ——> 解决方法： 加锁—拷贝。
- 调用线程不安全的函数。 ——> 解决方法： 使用上面三种方法，使之线程安全。

**死锁:**
- 死锁定义： 指的是一组 线程/进程被阻塞了，等待一个永远不会为真的条件。
- 死锁条件： 互斥条件， 不可抢占条件， 申请持有条件，循环等待条件。
- 防止死锁： 预防死锁， 避免死锁， 检测与恢复。
程序死锁的原因有很多，要避免死锁一般而言是很困难的。 然而，当使用二元信号量（或互斥锁）来实现互斥时，可以用以下方法避免死锁。

互斥锁加锁顺序规则: 如果对于程序中， 每对互斥锁(s, t)，给所有的锁分配一个全序，每个线程按照这个顺序来请求锁，并按照逆序来释放，那么这个程序就是无死锁的。

- [线程同步与安全总结](http://chenwenke.cn/blog/2017/08/19/thread-safe-and-sync/)
- [可重入，异步信号安全，线程安全概念区分](http://chenwenke.cn/blog/2017/05/01/reetrant-thread-safe-signal-safe/)

### select 和 epoll
select, pselect, poll, epoll 函数提供的功能都是类似的。允许进程指示内核等待多个事件中的任何一个发生，并只有在有一个或多个事件发生或经历一段指定的时间后才唤醒它。 

#### epoll 比 select快的原因
1. 在传入监听的描述符集合的时候，select 需要把三个集合拷贝进内核地址空间，并且这三个集合是**值-结果**的方式传递的。 select 返回的准备好的描述符会存储在其中。因此每次调用 select 都需要重新设置这三个集合。 
2. select 返回给用户态的只是可读可写的文件描述符总数，需要再使用 FD_ISSET 函数来检测哪些文件 I/O 可读，可写（遍历）。事实上，select比epoll慢的大部分开销都花费在遍历上面。监听的描述符越多，这种开销就越明显，也因此epoll更适合**监听的文件描述符很多，但是活跃连接不是很多的情况。**
3. epoll 在执行 epoll_create 时在内核的高速缓冲区里创建了一个红黑树和就绪链表，用户态传入的描述符被放到红黑树中，并注册描述符的回调函数。当描述符准备好后，调用回调函数把描述符放到就绪链表上。 
4. 插入或删除文件描述符的时候，直接在红黑树上进行查找和增删，并且传递描述符到用户态时，用的是 eventloop 文件系统，通过存储器映射，映射到用户空间，避免了拷贝开销。

- 另外，epoll支持两种触犯方式：水平触发和边缘触发。

在epoll里，水平触发表示只要有新数据了就通知（状态的改变）和“只要有新数据”就一直会通知。而边缘触发表示只有有新数据到达时才会通知。

举个具体的例子：如果某fd上有2kb的数据，应用程序只读了1kb，边缘触发就不会在下一次epoll_wait的时候返回，读完以后又有新数据才返回。而水平触发每次都会返回这个fd，只要这个fd有数据可读。

#### 在使用 epoll 的边沿触发时需要注意：
1. 把描述符设置成非阻塞的。
2. 在下次调用 epoll_wait前，要读或写到返回 EAGAIN.
3. 设置 EPOLLONESHOT, 完成读写后，调用 EPOLL_CTL_MOD. 
- 详细信息可以参看`man 7 epoll` 

select 允许建通的最大文件描述符数有上限，一般为 1024. 而 epoll 能达到系统允许打开的最大文件描述符数目。即： 65535（可以用 `cat /proc/sys/fs/file-max` 查看）

最后，当活动连接比较多的时候，epoll_wait的效率未必比select高，因为此时回调函数被触发的过于频繁。所以 epoll_wait 适用于连接数量多，但活动连接较少的情况。 

-[select /pselect / poll / epoll](http://chenwenke.cn/blog/2017/07/20/events-driver-models/)

### 进程与线程的区别

- 数据共享，同步：多进程中由于每个进程都有一个独立的虚拟地址空间，所以数据共享复杂，需要使用显式的IPC;但是由于数据是分开的，所以同步简单。 同一组中的多个线程共用同一个虚拟地址空间，因此共享数据比较简单，但是也正是因为这个原因导致同步复杂。 

- 内存，CPU: 多进程由于每个进程都有一个独立的页表，打开的文件描述符表结构等资源，所以占用的内存更多，切换复杂，CPU的利用率低。而多线程共享同一个页表， 打开的文件描述符表结构等资源，所以占用的内存较少，切换较简单，CPU的利用率较高。 

- 创建和销毁：由于进程占用的资源较多，所以创建，销毁，切换复杂，且执行这些操作的速度较慢。同理，线程执行这些操作的速度较快。

- 编程和调试： 多进程编程和调试简单。 多线程编程和调试复杂。

- 可靠性：多进程中，一个进程宕掉，一般不会影响其他进程。多线程中一个线程宕掉，会导致整个线程组（整个进程）宕掉。

- 分布式：多进程适应于多核，多机分布式；如果一台机器不够，扩展到多台机器比较简单。多线程适应于多核分布式，扩展到多台机器较复杂一些。
 

### 生产者-消费者模型

- [条件变量实现生产者-消费者模型](http://chenwenke.cn/blog/2017/07/15/mutex-condition-producer-customer/)
- [pthread_cond_wait详解](http://chenwenke.cn/blog/2017/09/09/thread_cond_wait/)


